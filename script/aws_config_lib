#!/bin/bash
##############################################################
##                                                          ##
##  This script is used for AWS Config functions            ##
##                                                          ##
##############################################################
. "${DOCKER_LIB}"

[ ! -f "$blj_aws_config" ] && blj_aws_config=~/.aws/aws_config

sheBang='#!/bin/bash'
IS_NULL="IS_NULL"
HN2_NUCL_DB="${BLJ_DEFAULT_DB}/chocophlan"
HN2_PROT_DB="${BLJ_DEFAULT_DB}/uniref"
STANDARD_CONFIG="${BLJ}/resources/config/default/standard.properties"
DOCKER_CONFIG="${BLJ}/resources/config/default/docker.properties"
alias awsr="aws_report_config"
alias awsrf="refresh_aws_cache"

# Archive previous AWS Config properties file: $blj_aws_config
# Param 1 - Run existing flag, if enabled, do not archive key.pem
aws_archive() {
	clear_aws_cache ${1}
	aws_history=~/.aws/history
	aws_log "Archive AWS properties, key file, and start script to $aws_history"
	[ ! -d $aws_history ] && mkdir $aws_history
	[ -f $blj_aws_config ] && mv $blj_aws_config $aws_history/aws_config-$(date "+%Y-%m-%d.%H.%M.%S")
	echo $sheBang > $blj_aws_config
	chmod 770 $blj_aws_config
	foundStartScript=$(ls ~/.aws | grep -c "run-bljStack" )
	[ ${foundStartScript} -gt 0 ] && mv ~/.aws/run-bljStack* $aws_history
	if [ $# -gt 0 ]; then 
		foundKeys=$(ls ~/.aws | grep -c ".pem" )
		[ ${foundKeys} -gt 0 ] && chmod 770 ~/.aws/*.pem && mv ~/.aws/*.pem $aws_history
	fi
}

# Get an AWS property ${1} from local AWS Config file ${2} under the awsProfile
# Param 1 - argName Parse filePath for a line that starts with argName
# Param 2 - filePath Target file
aws_local_prop() {
	[ ! -f "${2}" ] && aws_log "Error:  File not found: ${2}" && return
	foundProfile=0
	prop="$1 = "
	userProfile="[$(get_blj_prop awsProfile)]"
	cat "${2}" | while read -r line; do
		[ $foundProfile -eq 1 ] && [ "${line:0:1}" == "[" ] && break
		[ $foundProfile -eq 1 ] && [ "${line:0:${#prop}}" == "$prop" ] && echo "${line/$prop}" && return
		[ "$line" == "$userProfile" ] && foundProfile=1
	done
}

# Log current time-stamp and print the line parameter
# Param 1 - Log statement  
aws_log() {
	echo "[ $(date "+%Y-%m-%d %H:%M:%S") ] $1"
}

# Print AWS Config report
aws_report_config() {
	[ ! -f $blj_aws_config ] && echo "$blj_aws_config not found" && return
	aws_log "---------------------------------------------------"
	aws_log "Report current AWS Config"
	aws_log "---------------------------------------------------"
	tail -n +2 $blj_aws_config
	aws_log "---------------------------------------------------"
}

# Get the s3 bucket names in the user region
aws_s3_buckets() {
	myBuckets=$(aws s3api list-buckets --region $(get_blj_prop awsRegion) --query "Buckets[].Name")
	[ ${#myBuckets} -eq 0 ] || [ "$myBuckets" == "None" ] && return
	echo "${myBuckets}"
}

# Lists stacks available on AWS. If status arg provided, only return stacks with the given status.
# Param 1 (optional) Stack status
aws_stacks() {
	if [ ${#1} -gt 0 ]; then
		awsStacks=$(aws cloudformation describe-stacks --query "Stacks[?StackStatus=='$1'].StackName")
	else
		awsStacks=$(aws cloudformation describe-stacks --query "Stacks[].StackName")
	fi
	[ ${#awsStacks} -gt 0 ] && [ "${awsStacks}" != "None" ] && echo "${awsStacks}" && return
}

# Clear possible aws_config from bash shell memeroy
# Param 1 - (optional) flag to indciate re-use of existing stack
clear_aws_cache() {
	[ $# -eq 0 ] && awsAmi=
	[ $# -eq 0 ] && awsEc2InstanceID=
	[ $# -eq 0 ] && awsStack=
	[ $# -eq 0 ] && awsS3=
	awsEc2SpotPer=
	awsProfile=
	awsRam=
	awsRegion=
	awsWalltime=
	configFiles=
	dockerImgVersion=
	inputDirPaths=
	metadataFilePath=
	trimPrimersFilePath=
	kneaddataDbs=
	krakenDb=
	kraken2Db=
	metaphlan2Db=
	metaphlan2Mpa_pkl=
	qiimePynastAlignDB=
	qiimeRefSeqDB=
	qiimeTaxaDB=
	humann2NuclDB=
	humann2ProtDB=
	rdpDb=
}

# Convert pipeline Config DB prop to AWS Config file property format in: $blj_aws_config
# Param 1 - Pipeline Config file-path
# Param 2 - DB property name
convert_db_prop() {
	db=$(get_prop "${1}" "${2}")
	[ "$db" != "${BLJ_DEFAULT_DB}" ] && convert_prop "${1}" "${2}"
}

# Convert pipeline Config prop to AWS Config file property format in: $blj_aws_config
# Param 1 - Pipeline Config file-path
# Param 2 - property name
convert_prop() {
	val=$(get_prop "${1}" "${2}")
	[ $(echo "${val}" | wc -w) -gt 1 ] && val="'${val}'"
	set_blj_prop $(map_property_name "${2}") "${val}" $IS_NULL
}

# Get AWS-Access-ID from local file sytem (requires user has logged on to client or file is staged to $HOME)
get_aws_access_key_id() {
	echo $(aws_local_prop aws_access_key_id ~/.aws/credentials)
}

# Get AWS-Access-KEY from local file sytem (requires user has logged on to client or file is staged to $HOME)
get_aws_secret_access_key() {
	echo $(aws_local_prop aws_secret_access_key ~/.aws/credentials)
}

# Get the Pipeline Config local file-path
# Param 1 - local or ec2
get_config() {
	configFiles=$(get_blj_prop configFiles)
	propFiles=( ${configFiles//,/ } )
	numConfig=${#propFiles[@]}
	((numConfig--))
	[ "${1}" == "local" ] && echo "${propFiles[$numConfig]}"
	[ "${1}" == "ec2" ] && echo "${BLJ_CONFIG}/$(basename ${propFiles[$numConfig]})"
}

# Get the Config name - used to label pipeline dirs
get_config_name() {
	echo $(echo $(basename $(get_config local)) | cut -f1 -d".")
}

# Get a prop stored in $blj_aws_config
# Param 1 - Prop name
# Param 2 - (Optional) Default value
get_blj_prop() {
	val=$(get_prop $blj_aws_config "${1}")
	if [ ${#val} -eq 0 ]; then
		val="${2}"
		response=$(set_blj_prop "awsStack" "${2}")
	fi 
	echo "${val}"
}

# Return property value from the given file
# Param 1 - Config file
# Param 2 - Prop name
get_prop() {
	prop=$(cat "${1}" | grep ${2})
	out=$(eval "echo ${prop/${2}=}")
	[ "${out:0:1}" != "#" ] && echo "${out}"
}

# Init AWS Config properties file [ $blj_aws_config ] with pipeline Config, AWS config, and standard defaults
# Check BLJ pipeline Config files + all nested default Config files
# Add docker.properties if not already in list of nested Config files
# Param 1 - Pipeline Config file path
# Param 2 - Flag to use exsting AWS cloud
init_aws_config() {
	[ ! -f "${HOME}/.aws/config" ] && exit_script "Error [ aws_config_lib.init_aws_config() ]: Required file not found: ${HOME}/.aws/config"
	[ ! -f "${HOME}/.aws/credentials" ] && exit_script "Error [ aws_config_lib.init_aws_config() ]: Required file not found: ${HOME}/.aws/credentials"
	[ $# -eq 1 ] && aws_archive ${2}
	aws_log "Copy AWS properties from Pipeline Config \"$1\" into AWS Config --> \"$blj_aws_config\""
	set_pipeline_config_files "${1}"
	configFiles=$(get_blj_prop configFiles)
	if [ "${configFiles/docker.properties}" == "${configFiles}" ]; then
		[ ${#configFiles} -gt 0 ] && configFiles=",${configFiles}"
		configFiles="${DOCKER_CONFIG}${configFiles}" 
	fi
	if [ "${configFiles/standard.properties}" == "${configFiles}" ]; then
		[ ${#configFiles} -gt 0 ] && configFiles=",${configFiles}"
		configFiles="${STANDARD_CONFIG}${configFiles}" 
	fi
	propFiles=( ${configFiles//,/ } )
	for propFile in ${propFiles[@]}; do set_pipeline_conig_props $propFile; done
	verify_config
	aws_log "Pipeline Config properties initialized and saved to --> $blj_aws_config"
}

# Get the ec2 key file for the ec2 head node
key_file() {
	[ ${#awsStack} -eq 0 ] && refresh_aws_cache
	[ ${#awsStack} -eq 0 ] && exit_script "Error [ aws_config_lib.key_file() ]: Required AWS Config \"awsStack\" is undefined!"
	echo ~/.aws/${awsStack}.pem
}


# Get local Nextflow <base> config file
local_nf_conf() {
	NF_DIR=~/.aws/nextflow/${awsStack}
	[ ! -d $NF_DIR ] && mkdir -p $NF_DIR
	echo ~/.aws/nextflow/${awsStack}/config
}

# AWS Config prop names cannot contain "." or bash fails by trying to interpret and run them as function calls
# Param 1 - Prop name
map_property_name() {
	val=
	foundPeriod=N
	size=$((${#1}-1))
	for i in $(seq 0 $size); do
		char=${1:$i:1}
		if [ $foundPeriod == Y ]; then
			upCase=$(echo "${char}" | awk '{print toupper($0)}')
			val=${val}${upCase}
			foundPeriod=N
		elif [ "${char}" == "." ]; then
			foundPeriod=Y
		else
			val=${val}${char}
			foundPeriod=N
		fi
	done
	echo ${val}
}

# Refersh bash variables in memory via source $blj_aws_config
refresh_aws_cache() {
	. $blj_aws_config
}

# Remove AWS property - delete the line from the file
# Param 1 - Config file
# Param 2 - prop name 
rm_prop() {
	conf=$(cat "${1}")
	[ ${#conf} -eq 0 ] && return
	TMP=~/.temp_config.txt
	[ -f $TMP ] && rm $TMP
	touch $TMP && chmod 770 $TMP
	while read line; do 
		IFS2=$IFS && IFS=" "
		tokens=( ${line//=/ } )
		IFS=$IFS2
		[ "${tokens[0]}" != "${2}" ] && echo "${line}" >> $TMP
	done < "${1}"
	[ -f $TMP ] && rm "${1}" && mv $TMP "${1}"
}

# Call set_prop using Config file $blj_aws_config
# Param 1 - Prop name
# Param 2 - Prop value
# Param 3 - (optional) Default value
set_blj_prop() {
	[ ${#2} -eq 0 ] || [ "${2}" == $IS_NULL ] && return
	set_prop "$blj_aws_config" "${1}" "${2}"
}

# Set property in Config file ${1} unless this value already is set, in which case - do nothing.
# In case prop value ${3} is null, $3 actually returns the 4th param (the default)
# Param 1 - Config file-path
# Param 2 - Prop name
# Param 3 - Prop value
# Param 4 - (optional) Default value
set_prop() {
	line=$(cat "${1}" | grep "${2}")
	existsInFile=$(echo "${line}" | grep -c "${2}=${3}")
	paramIsNull=true
	[ ${#3} -gt 0 ] && [ "${3}" != $IS_NULL ] && paramIsNull=false
	[ ${existsInFile} -eq 0 ] && [ "$paramIsNull" == "true" ] && return
	rm_prop "${1}" "${2}"
	echo "${2}=${3}" >> "${1}"
}

# Set property "configFiles" as list of project Config files + nested default Config files.
# Files should be listed in order from standard.props up to project.props
# Param 1 - Pipeline Config file-path
set_pipeline_config_files() {
	aws_log "Search \"$1\" for nested \"pipeline.defaultProps\" Config files"
	configFiles="${1}"
	propFile=$(get_prop "${1}" "pipeline.defaultProps")
	while [ -f "$propFile" ]; do
		configFiles="$propFile,$configFiles"
		propFile=$(get_prop $propFile "pipeline.defaultProps")
	done
	aws_log "Save list of pipeline Config files configFiles=$configFiles"
	set_blj_prop configFiles "$configFiles"
}

# Save AWS Config properties in pipeline Config file to AWS Config file: $blj_aws_config
# Param 1 - Pipeline Config file path
set_pipeline_conig_props() {
	aws_log "Update \"$blj_aws_config\" with AWS properties found in Pipeline Config \"$1\""
	convert_prop "${1}" "aws.ami"
	convert_prop "${1}" "aws.ec2AcquisitionStrategy"
	convert_prop "${1}" "aws.ec2EndState"
	convert_prop "${1}" "aws.ec2InstanceID"
	convert_prop "${1}" "aws.ec2InstanceType"
	convert_prop "${1}" "aws.ec2SpotPer"
	convert_prop "${1}" "aws.profile"
	convert_prop "${1}" "aws.ram"
	convert_prop "${1}" "aws.region"
	convert_prop "${1}" "aws.stack"
	convert_prop "${1}" "aws.s3"
	convert_prop "${1}" "aws.walltime"
	convert_prop "${1}" "docker.imgVersion"
	convert_prop "${1}" "docker.user"
	convert_prop "${1}" "metadata.filePath"
	convert_prop "${1}" "trimPrimers.filePath"
	convert_prop "${1}" "input.dirPaths"
	convert_prop "${1}" "pipeline.downloadDir"
	convert_db_prop "${1}" "kneaddata.dbs"
	convert_db_prop "${1}" "kraken.db"
	convert_db_prop "${1}" "kraken2.db"
	convert_db_prop "${1}" "metaphlan2.db"
	convert_db_prop "${1}" "metaphlan2.mpa_pkl"
	convert_db_prop "${1}" "qiime.pynastAlignDB"
	convert_db_prop "${1}" "qiime.refSeqDB"
	convert_db_prop "${1}" "qiime.taxaDB"

	[ "$(get_prop ${1} humann2.nuclDB)" != "${HN2_NUCL_DB}" ] && convert_db_prop "${1}" "humann2.nuclDB"
	[ "$(get_prop ${1} humann2.protDB)" != "${HN2_PROT_DB}" ] && convert_db_prop "${1}" "humann2.protDB"
	aws_report_config
}

# Set basic defaults if undefined & throw error if user did not login to aws client or is missing required properties
verify_config() {
	refresh_aws_cache
	aws_log "Assign default AWS Config properties..."
	[ ${#awsProfile} -eq 0 ] && set_blj_prop awsProfile default
	[ ${#awsRegion} -eq 0 ] && set_blj_prop awsRegion $(aws configure get region)
	[ ${#awsEc2InstanceType} -eq 0 ] && set_blj_prop awsEc2InstanceType t2.micro
	[ ${#dockerImgVersion} -eq 0 ] && set_blj_prop dockerImgVersion latest
	[ ${#dockerUser} -eq 0 ] && set_blj_prop dockerUser biolockj
	access_id=$(get_aws_access_key_id)
	access_key=$(get_aws_secret_access_key)
	refresh_aws_cache
	aws_log "Verify AWS client authentication properties..."
	[ ${#awsRegion} -eq 0 ] && exit_script "Error [ aws_config_lib.verify_config() ]: Unable to find AWS Config \"aws.region\" in ~/.aws/config - please log into aws client from command line and try again."
	[ ${#access_id} -eq 0 ] && exit_script "Error [ aws_config_lib.verify_config() ]: Unable to find AWS Config \"aws_access_key_id\" in ~/.aws/credentials - please log into aws client from command line and try again."
	[ ${#access_key} -eq 0 ] && exit_script "Error [ aws_config_lib.verify_config() ]: Unable to find AWS Config \"aws_secret_access_key\" in ~/.aws/credentials - please log into aws client from command line and try again."
	aws_log "Verify basic required properties exist..."
	verify_ec2_acquisition_strategy
	verify_ec2_spot_per
	[ ${#awsRam} -eq 0 ] && exit_script "Error [ aws_config_lib.verify_config() ]: Required Pipeline Config property \"aws.ram\" undefined!"
}

# Verify the Pipeline Config property aws.ec2AcquisitionStrategy
verify_ec2_acquisition_strategy() {
	[ ${#awsEc2AcquisitionStrategy} -eq 0 ] && \
    exit_script "Error [ aws_config_lib.verify_ec2_acquisition_strategy() ]: Required property \"aws.ec2AcquisitionStrategy\" is undefined!"
	val=$(echo "${awsEc2AcquisitionStrategy}" | awk '{print toupper($0)}')
	[ "$val" != "SPOT" ] && [ "$val" != "DEMAND" ] && \
    exit_script "Error [ aws_config_lib.verify_ec2_acquisition_strategy() ]: Required property \"aws.ec2AcquisitionStrategy\" is invalid \"$val\".  Update to \"spot\" or \"demand\"!" 
}

# Verify the Pipeline Config property aws.ec2SpotPer
verify_ec2_spot_per() {
	ec2strategy=$( echo "${awsEc2AcquisitionStrategy}" | awk '{print toupper($0)}' )
	[ "${ec2strategy}" == "SPOT" ] && [ ${#awsEc2SpotPer} -eq 0 ] || [ ${awsEc2SpotPer} -lt 0 ] || [ ${awsEc2SpotPer} -gt 100 ] && \
    exit_script "Error [ aws_config_lib.verify_ec2_spot_per() ]: Dependent property \"aws.ec2SpotPer\" is required for \"aws.ec2AcquisitionStrategy=SPOT\".  Update to integer value in the range { 0 - 100 }"
}