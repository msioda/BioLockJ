#!/bin/bash
#####################################################################
##                                                                 ##
##  This script is used for uploading data + config to AWS cloud.  ##
##                                                                 ##
##                                                                 ##
#####################################################################
. $BLJ/script/aws_upload_lib

EC2_HEAD_NODE=/home/ec2-user
EFS=/mnt/efs
headConfig=$EFS/config
headScript=$EFS/script
headDB=$EFS/db
headInput=$EFS/input
headMeta=$EFS/metadata
headPrimer=$EFS/primer
headPipelines=$EFS/pipelines

# Build Docker Job defs to use with label references in Nextflow main.nf
build_docker_job_defs() {
	refresh_aws_cache
	dockerModules=$(docker search ${dockerUser} | grep -E ^${dockerUser} ) 
	jobVcpus=2
	jobRam=1024
	IFS=$'\t'
	[ ${#dockerModules} -eq 0 ] && aws_log "No Docker images found for Docker Account \"${dockerUser}\"" && return
	aws_log "Building job-definitions"
	echo ${dockerModules} | while read -r line; do
		[ $(echo $line | grep -c blj_basic) -gt 0 ] && continue
		module=$(echo $line | cut -f 1 -d " ")
		jobImg="${module}:${dockerImgVersion}"
		jobLabel=${jobImg/\//_} 
		jobLabel=${jobLabel/:/_} 
	    jobConfig="{ 
	    		\"image\": \"${jobImg}\",
			\"vcpus\": ${jobVcpus},
			\"memory\": ${jobRam},
			\"command\": [ \"/bin/bash\" ],
			\"jobRoleArn\": \"$(get_stack_param ECSTaskRole)\",
			\"volumes\": [ { \"host\": { \"sourcePath\": \"/mnt/efs\" }, \"name\": \"efs\" } ],
			\"mountPoints\": [ { \"containerPath\": \"/efs\", \"readOnly\": false, \"sourceVolume\": \"efs\" } ],
			\"readonlyRootFilesystem\": false,
			\"privileged\": true
		}"
		jobDef="${awsStack}_${jobLabel}"
		jobName=$(aws batch describe-job-definitions --status ACTIVE --job-definition-name ${jobDef} --query "jobDefinitions[*].jobDefinitionName")
		if [ ${#jobName} -eq 0 ]; then
			registeredJob=$(aws batch register-job-definition --job-definition-name $jobDef --type container --container-properties "${jobConfig}")
			jobName=$(echo $registeredJob | grep job-definition | sed 's/^.*job-definition/job-definition:\//' | awk '//{print $1}' )
			aws_log "Registered new Docker job-definition: ${jobName}"
		else
			aws_log "Found existing Docker job-definition: ${jobName}"
		fi
		prop=$(get_blj_prop "image_${jobLabel}" "${jobName}")
		aws_log "Saved Docker job-definition label: image_${jobLabel}=${prop}"
	done
	touch $(get_docker_job_flag)
}

# Create the basic nextflow config file using the current statck AWS batch queues
build_nextflow_config() {
	refresh_aws_cache
	nfConfig=$(get_nextflow_basic_config)
	dockUID="${dockerUser}"
	LPJQ="$(get_stack_param LowPriorityJobQueue)"
	HPJQ="$(get_stack_param HighPriorityJobQueue)"
	
	echo "# These Nextflow properties are inherited by pipeline main.nf" > $nfConfig
	echo "" >> $nfConfig
	echo "executor {" >> $nfConfig
    echo "    name = 'awsbatch'" >> $nfConfig
    echo "}" >> $nfConfig
    echo "" >> $nfConfig
    echo "aws {" >> $nfConfig
	echo "    region = '${awsRegion}'" >> $nfConfig
	echo "}" >> $nfConfig
	echo "" >> $nfConfig
	
	echo "process {" >> $nfConfig
	echo "    queue = '${LPJQ}'" >> $nfConfig
	echo "    withLabel: 'DEMAND' {" >> $nfConfig
	echo "        queue = '${HPJQ}'" >> $nfConfig
	echo "    }" >> $nfConfig

	while read line; do
	    line=$(echo ${line} | xargs)
	    prop=
	    val=
	    if [ "${line/=/}" != "${line}" ] && [ "${line:0:1}" != "#" ]; then
			prop=$(echo ${line} | cut -d '=' -f1)
			val=$(eval "echo ${line} | cut -d '=' -f2")
			if [ "${prop/image_$dockUID}" != "${prop}" ]; then
				echo "    withLabel: '${prop}' {" >> $nfConfig
				echo "        container = '${val}'" >> $nfConfig
				echo "    }" >> $nfConfig
			fi
		fi
	done < $blj_aws_config
	echo "}" >> $nfConfig
}

# Build start script for given Pipeline Config file and reutnr local path
# Param 1 - Pipeline Config file
build_start_script() {
	startScript=~/.aws/run-${awsStack}.sh
	[ -f "${metadataFilePath}" ] && meta="-m=$headMeta "
	echo $sheBang > $startScript
	echo "" >> $startScript
	echo "##########################################################" >> $startScript
	echo "##                                                      ##" >> $startScript
	echo "##  Run this script to launch BioLockJ pipeline on AWS  ##" >> $startScript
	echo "##  1) Clear old aws_manager Docker images (if any)     ##" >> $startScript
	echo "##  2) Pull the latest aws_manager from Docker Hub      ##" >> $startScript
	echo "##  3) Run dockblj                                      ##" >> $startScript
	echo "##                                                      ##" >> $startScript
	echo "##########################################################" >> $startScript
	echo "source /home/ec2-user/.bash_profile" >> $startScript
	echo 'images=$(docker images -f dangling=true -q)' >> $startScript
	echo '[ ${#images} -gt 0 ] && docker rmi $images' >> $startScript
	echo "docker pull ${dockerUser}/aws_manager:${dockerImgVersion}" >> $startScript
	echo "dockblj -aws ${meta}-i=$headInput -c=$(get_config)" >> $startScript
	chmod 770 $startScript
	echo $startScript
}

# Connect to running head node
connect_head() {
	aws_log "Opening SSH tunnel to Head Node...$(get_blj_prop publicHost)"
	ssh -o StrictHostKeyChecking=no -i $(key_file) ec2-user@$(get_blj_prop publicHost)
}

# Get the Pipeline Config local file-path
get_config() {
	configFiles=$(get_blj_prop configFiles)
	propFiles=( ${configFiles//,/ } )
	numConfig=${#propFiles[@]}
	((numConfig--))
	echo "$headConfig/$(basename ${propFiles[$numConfig]})"
}

# Get the flag file that indicates Docker job definitions were created
get_docker_job_flag() {
	echo ~/.aws/.$(get_blj_prop awsStack)-CREATED_DOCKER_JOB_DEFS
}

# Get a stack parameter for the configured stack 
# Param 1 - Param name
get_stack_param() {
	myParam=$(aws cloudformation describe-stacks --stack-name $(get_blj_prop awsStack) --query "Stacks[*].Outputs[?OutputKey=='$1'].OutputValue")
	[ ${#myParam} -eq 0 ] && return
	echo "${myParam}"
}

# Launch a new ec2 head node
launch_ec2_head_node() {
	[ -x "$(which docker)" ] && build_docker_job_defs && build_nextflow_config
	refresh_aws_cache
	runTime=0
	secureGroup="$(get_stack_param BastionSecurityGroup)"
	subnet="$(get_stack_param Subnet1)"
	templateId="$(get_stack_param HeadNodeLaunchTemplateId)"
	if [ ${#awsAmi} -eq 0 ] || [ ${#awsStack} -eq 0 ] || [ ${#secureGroup} -eq 0 ] || [ ${#subnet} -eq 0 ] || [ ${#templateId} -eq 0 ]; then
		exit_script "Error [ aws_head_node_lib.launch_ec2_head_node() ]: Cannot launch EC2 - required parameters not found in $blj_aws_config"
	fi
	instanceID=$(aws ec2 run-instances --count 1 --key-name ${awsStack} --image-id ${awsAmi} --security-group-ids ${secureGroup} \
		--tag-specifications "ResourceType=instance,Tags={Key=Name,Value='Head-${awsStack}'}" --subnet-id ${subnet} \
		--launch-template LaunchTemplateId=${templateId} --instance-type "${awsEc2InstanceType}" --query "Instances[].InstanceId" )
	printf "Launching EC2 Instance, please wait."
	systemStatus=init
	while [ "$systemStatus" != "ok" ]; do
		systemStatus=$(aws ec2 describe-instance-status --instance-ids ${instanceID} --query "InstanceStatuses[*].SystemStatus.Status")
		printf "."
		sleep 10s
		runTime=$((runTime+10))  
	done
	aws_log "InstanceID [ ${instanceID} ] created in $runTime seconds!"
	set_blj_prop instanceID ${instanceID}
	set_blj_prop publicHost $(aws ec2 describe-instances --instance-ids ${instanceID} --query "Reservations[].Instances[].PublicDnsName")
	refresh_aws_cache
	keyFound=$(cat ~/.ssh/known_hosts| grep -c ${publicHost})
	[ ${keyFound} -gt 0 ] && ssh-keygen -f ~/.ssh/known_hosts -R ${publicHost}
	startScript=$(build_start_script)
	stage_pipeline_on_aws $startScript
	if [ -x "$(which docker)" ]; then
		exe_remote_cmd "$EC2_HEAD_NODE/$(basename $startScript)"
	else
		connect_head
	fi
}
