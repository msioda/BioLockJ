#!/bin/bash
##############################################################
##                                                          ##
##  This script is used for AWS core function + logic       ##
##                                                          ##
##############################################################
. $BLJ/script/aws_config_functions

# Build the compute environment
build_compute_env() {
	compEnv=$(named_arg "$aws_args" computeEnv)
	myCompEnv=$(aws batch describe-compute-environments --compute-environments $compEnv --query "computeEnvironments[].computeEnvironmentName")
	if [ ${#myCompEnv} -eq 0 ] || [ "$myCompEnv" == "None" ]; then
		echo "Building $compEnv"
		ec2Type=$(named_arg "$aws_args" ec2Type)
		ami=$(named_arg "$aws_args" ami)
		subNet=$(named_arg "$aws_args" subNet)
		batchGroup=$(named_arg "$aws_args" batchGroup)
		keyName=$(named_arg "$aws_args" keyName)
		instanceRole=$(named_arg "$aws_args" instanceRole)
		ec2SpotPer=$(named_arg "$aws_args" ec2SpotPer)
		iamFleetRole=$(named_arg "$aws_args" iamFleetRole)
		batchNodeLaunchTemplate=$(named_arg "$aws_args" batchNodeLaunchTemplate)
		c1="type=$ec2Type,minvCpus=0,maxvCpus=112,desiredvCpus=0,instanceTypes=optimal,imageId=$ami,subnets=$subNet,"
		c2="securityGroupIds=$batchGroup,ec2KeyPair=$keyName,instanceRole=$instanceRole,bidPercentage=$ec2SpotPer,"
		c3="spotIamFleetRole=$iamFleetRole,launchTemplate={launchTemplateId=$batchNodeLaunchTemplate}"
		compResources=${c1}${c2}${c3}
		echo $(aws batch create-compute-environment --compute-environment-name $compEnv \
			--type MANAGED --state ENABLED --service-role $(named_arg "$aws_args" serviceRole) \
			--compute-resources "$compResources")
	else
		echo "Found stack compute environment: $myCompEnv"
	fi
}

# Build Docker Job defs to use with label references in Nextflow main.nf
build_docker_job_defs() {
	stack=$(named_arg "$aws_args" stack)
	jobRoleArn=$(named_arg "$aws_args" jobRoleArn)
	dockId=$(named_arg "$aws_args" dockerAccount)
	dockerVer=$(named_arg "$aws_args" dockerImgVer)
	dockerModules=$(docker search $dockId | grep -E ^$dockId ) 
	jobVcpus=2
	jobRam=1024
	IFS=$'\t'
	echo $dockerModules | while read -r line; do
		#echo "Read line: $line"
		[ $(echo "$line" | grep -c "blj_basic") -gt 0 ] && continue
		module=$(echo "$line" | cut -f 1 -d " ")
		#echo "Found module: $module (size=${#module})"
		jobImg="${module}:${dockerVer}"
		jobLabel=${module/\//_} 
		jobLabel=${jobLabel/:/_} 
		jobDef="${stack}_${jobLabel}"
		
	    jobConfig="{
			\"image\": \"$jobImg\",
			\"vcpus\": $jobVcpus,
			\"memory\": $jobRam,
			\"command\": [ \"/bin/bash\" ],
			\"jobRoleArn\": \"$jobRoleArn\",
			\"volumes\": [ { \"host\": { \"sourcePath\": \"/mnt/efs\" }, \"name\": \"efs\" } ],
			\"mountPoints\": [ { \"containerPath\": \"/efs\", \"readOnly\": false, \"sourceVolume\": \"efs\" } ],
			\"readonlyRootFilesystem\": false,
			\"privileged\": true
		}"
		
		#echo "jobImg: $jobImg"
		#echo "jobLabel: $jobLabel"
		#echo "jobDef: $jobDef"
		#echo "jobConfig: $jobConfig" 
		
		existingJob=$(aws batch describe-job-definitions --status ACTIVE --job-definition-name "$stack_$jobLabel" --query "jobDefinitions[*].jobDefinitionName")
		[ ${#existingJob} -gt 0 ] && echo "FOUND JOB: $existingJob" && continue
		registeredJob=$(aws batch register-job-definition --job-definition-name $jobDef --type container --container-properties "${jobConfig}")
		#echo "registeredJob: $registeredJob"
		IFS=$'\t' && OFS=$'\t'
		jobName=$(echo $registeredJob | grep job-definition | sed 's/^.*job-definition/job-definition:\//' | awk '//{print $1}' )
		echo "image_$jobLabel=$jobName"
	done

}

# Build Cloud-formation Stack
build_stack() {
	stack=$(named_arg "$aws_args" stack)
	[ $(is_stack_complete $stack) == "true" ] && echo "Found existing AWS Stack: $stack" && return 
	echo "Building cloud formation stack: $stack. Please wait..."
	stackYml="file://$BLJ/resources/aws/StackEFS.yml"
	myIp=$(get_ip)/32
	params='ParameterKey=NetworkAccessIP,ParameterValue='
	aws cloudformation create-stack --template-body $stackYml --stack-name $stack --capabilities CAPABILITY_IAM --parameters ${params}${myIp}
	numSecs=0
	echo "Building Stack: $stack"
	while [ $(is_stack_complete $stack) != "true" ]; do
		printf "." && sleep 5s && numSecs=$((numSecs+5))
	done
	echo "Secured to local IP: $myIp in $numSecs seconds"
}

# Build key pair + save to $aws_home_dir/$keyPair.pem file
cache_key_pair() {
	keyPair=$(named_arg "$aws_args" keyName)
	keyFile=$aws_home_dir/$keyPair.pem
	if [ ! -f $keyFile ]; then
		keys=$(aws ec2 describe-key-pairs)
		if [ "${keys/$keyPair}" == "$keys" ]; then
			aws ec2 create-key-pair --key-name $keyPair --query "KeyMaterial" > $keyFile
			echo "Security keys created.  Private key: $keyFile"
			#AWS keypair security requirement (perms 400)  
			chmod 400 $keyFile
			echo "Generated new: $keyFile"
		fi
	else
		echo "Found existing: $keyFile"
	fi
}

# Generate a name not found in $1, created using format $2-$date-index
# Param 1 (required) Key String
# Param 2 (optional) List of unavailable names
generate_name() {
	testVal="$1-$(date +%F)"
	[ $# -eq 1 ] && echo $testVal && return
	i=0
	maxI=1000
	while [ $i -lt $maxI ]; do
		[ "${2/$testVal}" == "$2" ] && echo $testVal && return
		i=$[$i+1] && testVal="$1-$(date +%F)-$i"
	done
	[ $i -eq $maxI ] && echo "Error:  Failed to generate unique name: $maxI names already exist!" && exit 1
}

# Get current IP address
get_ip() {
	echo $(curl -s checkip.dyndns.org | sed -e 's/.*Current IP Address: //' -e 's/<.*$//' )
}

# Get the s3 bucket for pipeline output, if no bucket name specified, a new bucket is created
# Param 1 (optional) S3 bucket name
get_s3() {
	s3Bucket=
	if [ $# -eq 1 ]; then
		s3Bucket=$(aws s3api list-buckets --region $(aws_region) --query "Buckets[?Name=='$1']|[*].Name")
		if [ ${#s3Bucket} -eq 0 ] || [ "$s3Bucket" == "None" ]; then
			echo "Error:  S3 bucket [ aws.s3=$1 ] not found" && exit 1
		fi
	else
		newS3=$(generate_name blj $(aws_s3_buckets))
		s3Bucket=$(aws s3api create-bucket --region $(aws_region) --bucket $newS3)
		if [ ${#s3Bucket} -eq 0 ] || [ "$s3Bucket" == "None" ]; then
			echo "Error:  Failed to create S3 bucket: $newS3" && exit 1
		fi
	fi
	echo $s3Bucket
}

# Return stack name.  If stack name arg given, verify is exists, else generate a new stack stack name.
# Param 1 (optional) Stack name
get_stack_name() {
	if [ $# -eq 0 ]; then
		awsStacks=$(aws_stacks CREATE_COMPLETE)
		echo $(generate_name bljStack $awsStacks)
	elif [ $# -eq 1 ]; then
		awsStacks=$(aws_stacks CREATE_COMPLETE)
		[ "${awsStacks/$1}" == "$awsStacks" ] && echo "Error:  Config property [ aws.stack=$1 ] does not exist!" && exit 1
		echo $1
	fi
}

# Check status of Cloud Formation Stack
# Param 1 Stack name
is_stack_complete() {
	stacks=$(aws cloudformation describe-stacks --query "Stacks[].StackName")
	[ ${#stacks} -eq 0 ] || [ "$stacks" == "None" ] || [ ${#1} -eq 0 ] && echo "false" && return
	stacks=$(aws cloudformation describe-stacks --stack-name $1 --query "Stacks[?StackStatus=='CREATE_COMPLETE']|[*].StackName")
	[ ${#stacks} -eq 0 ] || [ "$stacks" == "None" ] && echo "false" && return
	[ ${#stacks} -gt 0 ] && echo "true"
}

# Main method, called to launch BioLockJ on AWS
# Params format:  argName=argValue --> for example [ aws.s3=blj-2019-03-24 ]
# Params (required) Config property: aws.ec2InstanceType, aws.ec2SpotPer, aws.profile, docker.imgVersion
# Params (optional) Config properties that generate vals if undefined: aws.stack, aws.s3 

run_aws() {
	init_aws_config "$@" && aws_dev_config && set_account_config && build_stack && set_stack_config && \
		save_aws_config && cache_key_pair && build_compute_env && build_docker_job_defs && echo "run_aws COMPLETE!"
}
