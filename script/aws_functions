#!/bin/bash
##############################################################
##                                                          ##
##  This script is used for AWS core function + logic       ##
##                                                          ##
##############################################################
. $BLJ/script/aws_select_functions

# Build the compute environment
build_compute_env() {
	compEnv=$(named_arg "$aws_args" computeEnv)
	myCompEnv=$(aws batch describe-compute-environments --compute-environments $compEnv --query "computeEnvironments[].computeEnvironmentName")
	if [ ${#myCompEnv} -eq 0 ] || [ "$myCompEnv" == "None" ]; then
		echo "Building $compEnv"
		
		ec2Type=$(named_arg "$aws_args" ec2Type)
		ami=$(named_arg "$aws_args" ami)
		subNet=$(named_arg "$aws_args" subNet)
		batchGroup=$(named_arg "$aws_args" batchGroup)
		keyName=$(named_arg "$aws_args" keyName)
		instanceRole=$(named_arg "$aws_args" instanceRole)
		ec2SpotPer=$(named_arg "$aws_args" ec2SpotPer)
		iamFleetRole=$(named_arg "$aws_args" iamFleetRole)
		batchNodeLaunchTemplate=$(named_arg "$aws_args" batchNodeLaunchTemplate)
		c1="type=$ec2Type,minvCpus=0,maxvCpus=112,desiredvCpus=0,instanceTypes=optimal,imageId=$ami,subnets=$subNet,"
		c2="securityGroupIds=$batchGroup,ec2KeyPair=$keyName,instanceRole=$instanceRole,bidPercentage=$ec2SpotPer,"
		c3="spotIamFleetRole=$iamFleetRole,launchTemplate={launchTemplateId=$batchNodeLaunchTemplate}"
		compResources=${c1}${c2}${c3}
		
		echo $(aws batch create-compute-environment --compute-environment-name $compEnv \
			--type MANAGED --state ENABLED --service-role $(named_arg "$aws_args" serviceRole) \
			--compute-resources "$compResources")
	fi
}

# Build Docker Job defs to use with label references in Nextflow main.nf
build_docker_job_defs() {
	stack=$(named_arg "$aws_args" stack)
	jobRoleArn=$(named_arg "$aws_args" jobRoleArn)
	dockId=$(named_arg "$aws_args" dockerAccount)
	dockerVer=$(named_arg "$aws_args" dockerImgVer)
	dockerModules=$(docker search $dockId | grep ^$dockId | awk '{print $1}')
	jobVcpus=2
	jobRam=1024
	echo $ | while read -r line; do
		[ "${line/blj_basic}" != "$line" ] && continue
		jobImg="${line}:${dockerVer}"
		jobImgClean=$(tr -s /: _ <<< "$jobImg")
		jobDef="${stack}_${jobImgClean}"
	    jobConfig="{
			\"image\": \"$jobImg\",
			\"vcpus\": $jobVcpus,
			\"memory\": $jobRam,
			\"command\": [ \"/bin/bash\" ],
			\"jobRoleArn\": \"$jobRoleArn\",
			\"volumes\": [ { \"host\": { \"sourcePath\": \"/mnt/efs\" }, \"name\": \"efs\" } ],
			\"mountPoints\": [ { \"containerPath\": \"/efs\", \"readOnly\": false, \"sourceVolume\": \"efs\" } ],
			\"readonlyRootFilesystem\": false,
			\"privileged\": true
		}"
		echo "Created jobConfig: $jobConfig for $jobImg" 
		
		jobExists=$(aws batch describe-job-definitions --status ACTIVE --type container --query "jobDefinitions[].containerProperties=[?image='$jobImg']|[*].jobDefinitionName" )
		jobDefinitions
		
		registeredJob=$(aws batch register-job-definition --job-definition-name $jobDef --type container --container-properties "${jobConfig}")
		echo "registeredJob: $registeredJob"
		IFS=$'\t' && OFS=$'\t'
		jobName=$(echo $registeredJob | grep job-definition | sed 's/^.*job-definition/job-definition:\//' | awk '//{print $1}' )
		echo "image_$jobImgClean=$jobName"
	done
}

# Build Cloud-formation Stack
build_stack() {
	stack=$(named_arg "$aws_args" stack)
	[ $(is_stack_complete $stack) == "true" ] && echo "Found existing AWS Stack: $stack" && return 
	echo "Building cloud formation stack: $stack. Please wait..."
	stackYml="file://$BLJ/resources/aws/StackEFS.yml"
	myIp=$(get_ip)/32
	params='ParameterKey=NetworkAccessIP,ParameterValue='
	aws cloudformation create-stack --template-body $stackYml --stack-name $stack --capabilities CAPABILITY_IAM --parameters ${params}${myIp}
	numSecs=0
	echo "Building Stack: $stack"
	while [ $(is_stack_complete $stack) != "true" ]; do
		printf "." && sleep 5s && numSecs=$((numSecs+5))
	done
	echo "Secured to local IP: $myIp in $numSecs seconds"
}

# Build key pair + save to $local_aws_dir/$keyPair.pem file
cache_key_pair() {
	keyPair=$(named_arg "$aws_args" keyName)
	keyFile=$local_aws_dir/$keyPair.pem
	if [ ! -f $keyFile ]; then
		keys=$(aws ec2 describe-key-pairs)
		if [ "${keys/$keyPair}" == "$keys" ]; then
			aws ec2 create-key-pair --key-name $keyPair --query "KeyMaterial" > $keyFile
			echo "Security keys created.  Private key: $keyFile"
			#AWS keypair security requirement (perms 400)  
			chmod 400 $keyFile
		fi
	fi
}

# Generate a name not found in $1, created using format $2-$date-index
# Param 1 (required) Key String
# Param 2 (optional) List of unavailable names
generate_name() {
	testVal="$1-$(date +%F)"
	[ $# -eq 1 ] && echo $testVal && return
	i=0
	maxI=1000
	while [ $i -lt $maxI ]; do
		[ "${2/$testVal}" == "$2" ] && echo $testVal && return
		i=$[$i+1] && testVal="$1-$(date +%F)-$i"
	done
	[ $i -eq $maxI ] && echo "Error:  Failed to generate unique name: $maxI names already exist!" && exit 1
}

# Get current IP address
get_ip() {
	echo $(curl -s checkip.dyndns.org | sed -e 's/.*Current IP Address: //' -e 's/<.*$//' )
}

# Get the s3 bucket for pipeline output, if no bucket name specified, a new bucket is created
# Param 1 (optional) S3 bucket name
get_s3() {
	s3Bucket=
	if [ $# -eq 1 ]; then
		s3Bucket=$(aws s3api list-buckets --region $(aws_region) --query "Buckets[?Name=='$1']|[*].Name")
		if [ ${#s3Bucket} -eq 0 ] || [ "$s3Bucket" == "None" ]; then
			echo "Error:  S3 bucket [ aws.s3=$1 ] not found" && exit 1
		fi
	else
		newS3=$(generate_name blj $(aws_s3_buckets))
		s3Bucket=$(aws s3api create-bucket --region $(aws_region) --bucket $newS3)
		if [ ${#s3Bucket} -eq 0 ] || [ "$s3Bucket" == "None" ]; then
			echo "Error:  Failed to create S3 bucket: $newS3" && exit 1
		fi
	fi
	echo $s3Bucket
}

# Return stack name.  If stack name arg given, verify is exists, else generate a new stack stack name.
# Param 1 (optional) Stack name
get_stack_name() {
	if [ $# -eq 0 ]; then
		awsStacks=$(aws_stacks CREATE_COMPLETE)
		echo $(generate_name bljStack $awsStacks)
	elif [ $# -eq 1 ]; then
		awsStacks=$(aws_stacks CREATE_COMPLETE)
		[ "${awsStacks/$1}" == "$awsStacks" ] && echo "Error:  Config property [ aws.stack=$1 ] does not exist!" && exit 1
		echo $1
	fi
}

# Check status of Cloud Formation Stack
# Param 1 Stack name
is_stack_complete() {
	stackExists=$( echo $(aws cloudformation describe-stacks --query "Stacks[].StackName") | grep -c $1 )
	[ ${#stackExists} -gt 0 ] && testStack=$(aws cloudformation describe-stacks --stack-name $1 \
		--query "Stacks[?StackStatus=='CREATE_COMPLETE']|[*].StackName")
	[ ${#testStack} -eq 0 ] || [ "$testStack" == "None" ] && echo "false"
	[ ${#testStack} -gt 0 ] && echo "true"
}

# Main method, called to launch BioLockJ on AWS
# Params format:  argName=argValue --> for example [ aws.s3=blj-2019-03-24 ]
# Params (required) Config property: aws.ec2InstanceType, aws.ec2SpotPer, aws.profile, docker.imgVersion
# Params (optional) Config properties that generate vals if undefined: aws.stack, aws.s3 

run_aws() {
	init_aws_config "$@" && aws_dev_config && set_account_config && build_stack && set_stack_config && \
		save_aws_config && cache_key_pair && build_compute_env && build_docker_job_defs
}

# Build account config (and create s3 bucket if needed)
set_account_config() {
	set_aws_config access_id $(aws_local_prop aws_access_key_id $aws_cred_file)
	set_aws_config key $(aws_local_prop aws_secret_access_key $aws_cred_file)
	set_aws_config ami $(aws_ami)
	set_aws_config s3Bucket $(get_s3 $(named_arg "$aws_args" myS3))
	set_aws_config stack $(get_stack_name $(named_arg "$aws_args" stackName))
	remove_aws_config stackName
}
