#!/bin/bash
##############################################################
##                                                          ##
##  This script is used for AWS core function + logic       ##
##                                                          ##
##############################################################
. $BLJ/script/aws_config_functions

# Build the compute environment
build_compute_env() {
	. $blj_aws_config
	myCompEnv=$(aws batch describe-compute-environments --compute-environments $compEnv --query "computeEnvironments[].computeEnvironmentName")
	if [ ${#myCompEnv} -eq 0 ] || [ "$myCompEnv" == "None" ]; then
		echo "Building $compEnv"
		c1="type=$ec2Type,minvCpus=0,maxvCpus=112,desiredvCpus=0,instanceTypes=optimal,imageId=$ami,subnets=$subnet,"
		c2="securityGroupIds=$bastionGroup,ec2KeyPair=$keyName,instanceRole=$instanceRole,bidPercentage=$ec2SpotPer,"
		c3="spotIamFleetRole=$iamFleetRole,launchTemplate={launchTemplateId=$batchNodeLaunchTemplate}"
		compResources=${c1}${c2}${c3}
		echo $(aws batch create-compute-environment --compute-environment-name $compEnv \
			--type MANAGED --state ENABLED --service-role $serviceRole --compute-resources "$compResources")
	else
		echo "Found existing compute environment: $myCompEnv"
	fi
}

# Build Docker Job defs to use with label references in Nextflow main.nf
build_docker_job_defs() {
	. $blj_aws_config
	dockerModules=$(docker search $dockerUser | grep -E ^$dockerUser ) 
	jobVcpus=2
	jobRam=1024
	IFS=$'\t'
	echo "Building job-definitions"
	echo $dockerModules | while read -r line; do
		[ $(echo $line | grep -c blj_basic) -gt 0 ] && continue
		module=$(echo $line | cut -f 1 -d " ")
		jobImg="${module}:${dockerImgVersion}"
		jobLabel=${jobImg/\//_} 
		jobLabel=${jobLabel/:/_} 
	    jobConfig="{ 
	    		\"image\": \"$jobImg\",
			\"vcpus\": $jobVcpus,
			\"memory\": $jobRam,
			\"command\": [ \"/bin/bash\" ],
			\"jobRoleArn\": \"$jobRoleArn\",
			\"volumes\": [ { \"host\": { \"sourcePath\": \"/mnt/efs\" }, \"name\": \"efs\" } ],
			\"mountPoints\": [ { \"containerPath\": \"/efs\", \"readOnly\": false, \"sourceVolume\": \"efs\" } ],
			\"readonlyRootFilesystem\": false,
			\"privileged\": true
		}"
		jobDef="${awsStack}_${jobLabel}"
		existingJob=$(aws batch describe-job-definitions --status ACTIVE --job-definition-name $jobDef --query "jobDefinitions[*].jobDefinitionName")
		[ ${#existingJob} -gt 0 ] && echo "FOUND JOB: $existingJob" && continue
		registeredJob=$(aws batch register-job-definition --job-definition-name $jobDef --type container --container-properties "${jobConfig}")
		jobName=$(echo $registeredJob | grep job-definition | sed 's/^.*job-definition/job-definition:\//' | awk '//{print $1}' )
		echo "image_$jobLabel=$jobName"
	done

}

# Build Cloud-formation Stack
build_stack() {
	awsStack=$(get_blj_prop awsStack)
	[ $(is_stack_complete $awsStack) == "true" ] && echo "Found existing AWS Stack: $awsStack" && return 
	echo "Building cloud formation stack: $awsStack. Please wait..."
	stackYml="file://$BLJ/resources/aws/StackEFS.yml"
	myIp=$(get_ip)/32
	params='ParameterKey=NetworkAccessIP,ParameterValue='
	aws cloudformation create-stack --template-body $stackYml --stack-name $awsStack --capabilities CAPABILITY_IAM --parameters ${params}${myIp}
	numSecs=0
	echo "Building Stack: $awsStack"
	while [ $(is_stack_complete $awsStack) != "true" ]; do
		printf "." && sleep 5s && numSecs=$((numSecs+5))
	done
	echo "Secured to local IP: $myIp in $numSecs seconds"
}

# Build key pair + save to $aws_home_dir/$keyPair.pem file
cache_key_pair() {
	keyPair=$(get_blj_prop keyName)
	keyFile=$aws_home_dir/$keyPair.pem
	if [ ! -f $keyFile ]; then
		keys=$(aws ec2 describe-key-pairs)
		if [ "${keys/$keyPair}" == "$keys" ]; then
			aws ec2 create-key-pair --key-name $keyPair --query "KeyMaterial" > $keyFile
			echo "Security keys created.  Private key: $keyFile"
			#AWS keypair security requirement (perms 400)  
			chmod 400 $keyFile
			echo "Generated new: $keyFile"
		fi
	else
		echo "Found existing: $keyFile"
	fi
}

# Connect to runninng head node
connect_head() {
	ssh -i $(key_file) ec2-user@$(get_blj_prop publicHost)
}

# Generate a name not found in $1, created using format $2-$date-index
# Param 1 (required) Key String
# Param 2 (optional) List of unavailable names
generate_name() {
	testVal="$1-$(date +%F)"
	[ $# -eq 1 ] && echo $testVal && return
	i=0
	maxI=1000
	while [ $i -lt $maxI ]; do
		[ "${2/$testVal}" == "$2" ] && echo $testVal && return
		i=$[$i+1] && testVal="$1-$(date +%F)-$i"
	done
	[ $i -eq $maxI ] && echo "Error:  Failed to generate unique name: $maxI names already exist!" && exit 1
}

# Get current IP address
get_ip() {
	echo $(curl -s checkip.dyndns.org | sed -e 's/.*Current IP Address: //' -e 's/<.*$//' )
}

# Get the s3 bucket for pipeline output, if no bucket name specified, a new bucket is created
# Param 1 (optional) S3 bucket name
get_s3() {
	s3Bucket=
	myS3=$(get_blj_prop awsS3)
	if [ ${#myS3} -gt 0 ]; then
		s3Bucket=$(aws s3api list-buckets --region $(get_blj_prop awsRegion)  --query "Buckets[?Name=='$myS3']|[*].Name")
		if [ ${#s3Bucket} -eq 0 ] || [ "$s3Bucket" == "None" ]; then
			echo "Error:  S3 bucket [ awsS3=$myS3 ] not found" && exit 1
		fi
	else
		newS3=$(generate_name blj $(aws_s3_buckets))
		s3Bucket=$(aws s3api create-bucket --region $(get_blj_prop awsRegion) --bucket $newS3)
		if [ ${#s3Bucket} -eq 0 ] || [ "$s3Bucket" == "None" ]; then
			echo "Error:  Failed to create S3 bucket: $newS3" && exit 1
		fi
	fi
	echo $s3Bucket
}

get_s3_buckets() {
	echo $(aws s3api list-buckets --region us-east-1 --query "Buckets[].Name")
}

# Return stack name.  If stack name arg given, verify is exists, else generate a new stack stack name.
# Param 1 (optional) Stack name
get_stack_name() {
	if [ $# -eq 0 ]; then
		awsStacks=$(aws_stacks CREATE_COMPLETE)
		echo $(generate_name bljStack $awsStacks)
	elif [ $# -eq 1 ]; then
		awsStacks=$(aws_stacks CREATE_COMPLETE)
		[ "${awsStacks/$1}" == "$awsStacks" ] && echo "Error:  Config property [ awsStack=$1 ] does not exist!" && exit 1
		echo $1
	fi
}

# Check status of Cloud Formation Stack
# Param 1 Stack name
is_stack_complete() {
	stacks=$(aws cloudformation describe-stacks --query "Stacks[].StackName")
	[ ${#stacks} -eq 0 ] || [ "$stacks" == "None" ] || [ ${#1} -eq 0 ] && echo "false" && return
	stacks=$(aws cloudformation describe-stacks --stack-name $1 --query "Stacks[?StackStatus=='CREATE_COMPLETE']|[*].StackName")
	[ ${#stacks} -eq 0 ] || [ "$stacks" == "None" ] && echo "false" && return
	[ ${#stacks} -gt 0 ] && echo "true"
}

# Get the ec2 key file for the ec2 head node
key_file() {
	echo $aws_home_dir/$(get_blj_prop keyName).pem
}

# Launch a new ec2 head node
launch_ec2_head_node() {
	. $blj_aws_config
	runTime=0
	instanceID=$(aws ec2 run-instances --count 1 --key-name $keyName --image-id $ami --security-group-ids $bastionGroup 
		--tag-specifications "ResourceType=instance,Tags={Key=Name,Value='HeadNode'}" --subnet-id $subnet
		--subnet-id $subnet --launch-template LaunchTemplateId=$headNodeLaunchTemplate --instance-type $ec2Category --query "Instances[].PrivateIpAddress" )

	echo "Launching EC2 Instance: $instanceID"
	systemStatus=starting
	while [ "$systemStatus" != "ok" ]; do
		systemStatus=$(aws ec2 describe-instance-status --instance-ids $instanceID --query "InstanceStatuses[*].SystemStatus.Status")
		printf "."
		sleep 10s
		runTime=$((runTime+10))
	done
	echo " Instance:  $instanceID created in $runTime seconds"
	set_blj_config instanceID $instanceID
	
	set_blj_config privateHost $(aws ec2 describe-instances --instance-ids $instanceID --query "Reservations[*].Instances[*].PrivateDnsName")
	set_blj_config privateIp $(aws ec2 describe-instances --instance-ids $instanceID --query "Reservations[].Instances[].PrivateIpAddress")
	set_blj_config publicIp $(aws ec2 describe-instances --instance-ids $instanceID --query "Reservations[].Instances[].PublicIpAddress")
	
	publicHost=$(set_blj_config publicHost $(aws ec2 describe-instances --instance-ids $instanceID --query "Reservations[].Instances[].PublicDnsName"))

	#remove previous hosts
	keyFound=$(cat ~/.ssh/known_hosts | grep -c ${publicHost})
	[ $keyFound -gt 0 ] && ssh-keygen -f ~/.ssh/known_hosts -R ${publicHost}

	echo "Connecting directly via ssh:"
	ssh -i $(key_file) ec2-user@${publicHost}
}

# Main method, called to launch BioLockJ on AWS from localhost, if a Config is not given, defaults are used.
# The optional file-path parameter can be passed to re-use existing objects on the cloud.
# The parameter file should contain AWS configuration properties in the expected format.
# Config file parameter format:  argName=argValue --> for example [ awsS3=blj-2019-03-24 ]
run_aws() {
	init_aws_config true && set_account_config && build_stack && set_stack_config && cache_key_pair && \
		build_compute_env && build_docker_job_defs && launch_ec2_head_node && echo "run_aws COMPLETE!"
}

# Build account config (and create s3 bucket if needed)
set_account_config() {

	set_blj_prop ami ami-007571470797b8ffa
	set_blj_prop awsStack bljStack-2019-03-27-2
	set_blj_prop awsS3 blj-2019-03-27-1
	
	stackName=$(get_blj_prop awsStack)
	
	x=$(get_blj_prop ami $(aws_get_ami))
	x=$(get_blj_prop awsS3 $(get_s3))
	x=$(get_blj_prop awsStack $(get_stack_name $stackName))
	
}

# Upload data to the ec2 head node
upload_to_head_node() {
	ssh -i $(key_file) ec2-user@$(get_blj_prop publicHost)
}
